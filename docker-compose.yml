services:
  # Zookeeper - Required for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - analytics-network
    healthcheck:
      test: nc -z localhost 2181 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka - Event streaming backbone
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_INTERNAL_ENDPOINT:-kafka:9092},PLAINTEXT_HOST://${KAFKA_EXTERNAL_ENDPOINT:-localhost:29092}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      analytics-network:
        aliases:
          - broker
    healthcheck:
      test: kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  # Postgres - Analytics data warehouse
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-analytics}
      POSTGRES_USER: ${POSTGRES_USER:-analytics}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-analytics_password}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgres_init:/docker-entrypoint-initdb.d
    networks:
      analytics-network:
        aliases:
          - database
    healthcheck:
      test: pg_isready -U analytics -d analytics
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI Ingestion Service - Receives analytics events
  ingestion-api:
    build:
      context: ./ingestion_api
      dockerfile: Dockerfile
    container_name: ingestion-api
    hostname: backend
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "${INGESTION_PORT:-8000}:8000"
    volumes:
      - ./global_config.yaml:/app/global_config.yaml:ro
    environment:
      - CONFIG_PATH=/app/global_config.yaml
    networks:
      analytics-network:
        aliases:
          - backend
    restart: unless-stopped

  # Python Consumer - Logs events to JSON files
  python-consumer:
    build:
      context: ./python_consumer
      dockerfile: Dockerfile
    container_name: python-consumer
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./global_config.yaml:/app/global_config.yaml:ro
      - logs-data:/data/logs
    environment:
      - CONFIG_PATH=/app/global_config.yaml
    networks:
      analytics-network:
        aliases:
          - log-writer
    restart: unless-stopped

  # PySpark ETL Job - Processes logs and computes analytics
  pyspark-cron:
    build:
      context: ./pyspark_cron
      dockerfile: Dockerfile
    container_name: pyspark-cron
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./global_config.yaml:/app/global_config.yaml:ro
      - logs-data:/data/logs
      - processed-data:/data/processed
      - tmp-data:/data/tmp
    environment:
      - CONFIG_PATH=/app/global_config.yaml
    networks:
      analytics-network:
        aliases:
          - etl
    restart: unless-stopped

  # Next.js Dashboard - Visualizes analytics data
  nextjs-dashboard:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: nextjs-dashboard
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=${POSTGRES_DB:-analytics}
      - POSTGRES_USER=${POSTGRES_USER:-analytics}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-analytics_password}
      - NEXT_PUBLIC_API_BASE_URL=${NEXT_PUBLIC_API_BASE_URL:-http://backend:${INGESTION_PORT:-8000}}
    networks:
      analytics-network:
        aliases:
          - frontend
    restart: unless-stopped

networks:
  analytics-network:
    driver: bridge

volumes:
  postgres-data:
  logs-data:
  processed-data:
  tmp-data:
